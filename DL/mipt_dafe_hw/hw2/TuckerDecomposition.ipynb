{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qjl6x6og3uXH"
      },
      "source": [
        "# HW 2 - Разложение матриц градиентным методом"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sv79QFb_-oNZ"
      },
      "source": [
        "Цель задания: В ходе реализации [разложения Таккера](https://proceedings.neurips.cc/paper/2018/file/45a766fa266ea2ebeb6680fa139d2a3d-Paper.pdf) градиентным методом освоить pyTorch и реализовать подходы оптимизации параметров модели (в отсутствии готовых решений)."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install tensorly"
      ],
      "metadata": {
        "id": "7cETheA1BbT0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1HUSrylpBwYn"
      },
      "source": [
        "[Более-менее внятное описание алгоритма канонического разложения](https://www.alexejgossmann.com/tensor_decomposition_tucker/) - само аналитическое разложение вам реализовывать НЕ НУЖНО"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P1PuoBtG7iw7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b72d60fd-1526-4cfb-846a-485863997201"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7c3ee857fdb0>"
            ]
          },
          "metadata": {},
          "execution_count": 412
        }
      ],
      "source": [
        "import random\n",
        "import time\n",
        "import torch\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import tensorly as tl\n",
        "from tensorly.decomposition import non_negative_tucker, non_negative_tucker_hals, tucker\n",
        "from tensorly.metrics.regression import RMSE\n",
        "\n",
        "import scipy.sparse as sparse\n",
        "from scipy.sparse.linalg import spsolve\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from matplotlib import pyplot as plt\n",
        "from numpy.linalg import svd, matrix_rank, pinv, inv\n",
        "from scipy.linalg import eigh, eig\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from tqdm.notebook import tqdm\n",
        "from torch import nn\n",
        "\n",
        "import math\n",
        "from torch.optim.optimizer import Optimizer\n",
        "import torch.nn.functional as F\n",
        "\n",
        "np.random.seed(0)\n",
        "torch.manual_seed(0)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OdgOrKhyCS6r",
        "outputId": "28bcd732-299a-4642-83c7-dfb89704148f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6LfhKpuX7htE"
      },
      "source": [
        "## 1 Создайте 3х мерный тензор\n",
        "Размер тензора не меньше 100 по каждой из размерностей.\n",
        "\n",
        "Заполните случайными целыми числами в диапазоне от 0 до 9."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ap1Ozn7P8-Yj"
      },
      "source": [
        "Примечание: разложение будет корректно работать со случайным тензором, только если изначально создавать случайные ядро и матрицы, а потом по ним формировать тензор. Работайте с типом *torch.Tensor.double*."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # Функция, восстанавливающая тензор по ядру и матрицам\n",
        "# def repair_tensor(G_, U):\n",
        "#     # data - восстановленный тензор из матриц и ядра\n",
        "#     # U - список матриц\n",
        "#     # G_ - ядро разложения\n",
        "#     a1 = tl.tenalg.mode_dot(tensor=tl.tensor(G_.detach().numpy()), matrix_or_vector=tl.tensor(U[0].detach().numpy()), mode=0, transpose=False)\n",
        "#     a2 = tl.tenalg.mode_dot(tensor=a1, matrix_or_vector=tl.tensor(U[1].detach().numpy()), mode=1, transpose=False)\n",
        "#     a3 = tl.tenalg.mode_dot(tensor=a2, matrix_or_vector=tl.tensor(U[2].detach().numpy()), mode=2, transpose=False)\n",
        "#     return torch.tensor(a3, dtype=torch.double, requires_grad=True, device=device)"
      ],
      "metadata": {
        "id": "IXgWKromr6Vi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5SzHzteOROQQ"
      },
      "outputs": [],
      "source": [
        "# Создадим тензор: размер тензора и r задаётся\n",
        "def get_tensor(size=(100,200,150), r=10):\n",
        "    # data - тензор с заданной размерностью\n",
        "    # U - список матриц\n",
        "    U = [torch.tensor(np.random.randint(10, size=(size[i], r)), dtype=torch.double, requires_grad=True, device=device) for i in range(len(size))]\n",
        "    # G - ядро разложения\n",
        "    G = torch.tensor(np.random.randint(10, size=(r, r, r)), dtype=torch.double, requires_grad=True, device=device)\n",
        "    data = rebuild_tensor(G, U)\n",
        "\n",
        "    return data, U, G"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def rebuild_tensor(G_, U):\n",
        "    result = G_\n",
        "    print(f\"Core tensor requires_grad: {G_.requires_grad}\")\n",
        "    for i, u in enumerate(U):\n",
        "        result = torch.tensordot(result, u, dims=([0], [1]))\n",
        "        print(f\"Factor {i} requires_grad: {u.requires_grad}\")\n",
        "    print(f\"result tensor requires_grad: {result.requires_grad}\")\n",
        "    return result"
      ],
      "metadata": {
        "id": "Q4Vqcg71SaaE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a = torch.tensor(np.random.normal(0, 1e-2, size=size), dtype=torch.double, device=device)\n",
        "a.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0PWe7UYJSm2a",
        "outputId": "995e39d2-3f67-4a5a-f276-b95f56412ad7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([10, 20, 30])"
            ]
          },
          "metadata": {},
          "execution_count": 417
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EFuFlp2n78Tz"
      },
      "source": [
        "Сгенерируйте тензор и добавьте к нему случайный шум с размерностью *1e-2*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FnUbbsYSdrsw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b4e72ee4-afde-4a5b-939e-6fcf95ab0437"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Core tensor requires_grad: True\n",
            "Factor 0 requires_grad: True\n",
            "Factor 1 requires_grad: True\n",
            "Factor 2 requires_grad: True\n",
            "result tensor requires_grad: True\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([10, 20, 30]),\n",
              " [torch.Size([10, 5]), torch.Size([20, 5]), torch.Size([30, 5])],\n",
              " torch.Size([5, 5, 5]))"
            ]
          },
          "metadata": {},
          "execution_count": 418
        }
      ],
      "source": [
        "# size = (100, 200, 300)\n",
        "# r = 10\n",
        "\n",
        "size = (10, 20, 30)\n",
        "r = 5\n",
        "\n",
        "data, U, G = get_tensor(size, r)\n",
        "data.shape, [u.shape for u in U], G.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N70Xy_6u9RFa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aabc0bfb-6727-4865-8e27-5e9810a0362c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "data_w_noise requires_grad: True\n"
          ]
        }
      ],
      "source": [
        "noise = torch.tensor(np.random.normal(0, 1e-2, size=size), dtype=torch.double, device=device)\n",
        "data_w_noise = data + noise\n",
        "print(f\"data_w_noise requires_grad: {data_w_noise.requires_grad}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kp75_Ad29RL5"
      },
      "source": [
        "Вопрос:\n",
        "Почему задание не имеет смысла для полностью случайного тензора и зачем добавлять шум? *не отвечать нельзя*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5VLMaT5wyE11"
      },
      "source": [
        "Ответ:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TzninpMYD_hd"
      },
      "source": [
        "## 2 Реализуйте метод для восстановления тензора по разложению"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YDTx9ZbYD-_S"
      },
      "outputs": [],
      "source": [
        "# Функция, восстанавливающая тензор по ядру и матрицам (для результата из библы tensorly)\n",
        "def repair_tensor_for_ndarray(G_, U):\n",
        "    # data - восстановленный тензор из матриц и ядра\n",
        "    # U - список матриц\n",
        "    # G_ - ядро разложения\n",
        "    a1 = tl.tenalg.mode_dot(tensor=tl.tensor(G_), matrix_or_vector=tl.tensor(U[0]), mode=0, transpose=False)\n",
        "    a2 = tl.tenalg.mode_dot(tensor=a1, matrix_or_vector=tl.tensor(U[1]), mode=1, transpose=False)\n",
        "    a3 = tl.tenalg.mode_dot(tensor=a2, matrix_or_vector=tl.tensor(U[2]), mode=2, transpose=False)\n",
        "    return torch.tensor(a3, dtype=torch.double)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MKqzxtaE-F16"
      },
      "source": [
        "## 3 Сделайте разложение библиотечным методом\n",
        "Пакет можете брать любой"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hlp4Jh3--fKh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ba0cc8f9-c105-400b-9fa0-23329c078df9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(5, 5, 5) [(10, 5), (20, 5), (30, 5)]\n"
          ]
        }
      ],
      "source": [
        "# использую tucker from tensorly\n",
        "data_ndarray = data_w_noise.detach().numpy()\n",
        "core, factors = tucker(tl.tensor(data_ndarray), [r, r, r])\n",
        "print(core.shape, [u.shape for u in factors])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wMw1x8w8-lsh"
      },
      "source": [
        "Не забудьте померить ошибку разложения по метрике MSE"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def MSE(tensor1, tensor2):\n",
        "    delta = tensor1-tensor2\n",
        "    delta *= delta\n",
        "    mse = delta.sum() / delta.numel()\n",
        "    return mse.item()"
      ],
      "metadata": {
        "id": "QaBCzVUcY5BH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HWkdb7Ip-mL3"
      },
      "outputs": [],
      "source": [
        "repaired_data = repair_tensor_for_ndarray(core, factors)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "MSE(repaired_data, data_w_noise)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xXz8pgtLXo09",
        "outputId": "a8a8b920-fa18-4e3d-8907-67f755315515"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "9.538384390111432e-05"
            ]
          },
          "metadata": {},
          "execution_count": 424
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ibOgeEgfD1wm"
      },
      "source": [
        "## 4 Реализуйте разложение градиентным методом"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GstBYmiBF7A6"
      },
      "source": [
        "### 4.1 Реализуйте *optimizer*\n",
        "Можно взять из исходников *PyTorch* и отнаследоваться от *torch.optim.optimizer*.\n",
        "Используйте квадратичный *Loss*."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mxrtt60hF6xb"
      },
      "outputs": [],
      "source": [
        "# class Opt(Optimizer):\n",
        "\n",
        "#     def __init__(self, params, lr=1e-3, ...):\n",
        "#         super().__init__(params, defaults)\n",
        "\n",
        "#     def step(self):\n",
        "#         return loss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8GSolH5dEJba"
      },
      "source": [
        "### 4.2 Реализуйте цикл оптимизации параметров"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P6UWpuERFTn8"
      },
      "source": [
        "Стоит параметры оптимизировать сразу на GPU"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class TuckerOptimizer(Optimizer):\n",
        "    def __init__(self, params, lr=1e-3):\n",
        "        defaults = {'lr': lr}\n",
        "        super().__init__(params, defaults)\n",
        "\n",
        "    # по мотивам доков sgd optimizer\n",
        "    def step(self, closure=None):\n",
        "        \"\"\"Perform a single optimization step.\n",
        "\n",
        "        Args:\n",
        "            closure (Callable, optional): A closure that reevaluates the model\n",
        "                and returns the loss.\n",
        "        \"\"\"\n",
        "        loss = None\n",
        "        if closure is not None:\n",
        "            with torch.enable_grad():\n",
        "                loss = closure()\n",
        "\n",
        "\n",
        "        for group in self.param_groups:\n",
        "            lr = group['lr']\n",
        "            for param in group['params']:\n",
        "                print(param.grad)\n",
        "                if param.grad is not None:\n",
        "                    param.data -= lr * param.grad\n",
        "\n",
        "        return loss\n"
      ],
      "metadata": {
        "id": "pz_Gt7mN1Tu8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def rebuild_tensor(G_, U):\n",
        "    result = G_\n",
        "    print(f\"Core tensor requires_grad: {G_.requires_grad}\")\n",
        "    for i, u in enumerate(U):\n",
        "        result = torch.tensordot(result, u, dims=([0], [1]))\n",
        "        print(f\"Factor {i} requires_grad: {u.requires_grad}\")\n",
        "    print(f\"result tensor requires_grad: {result.requires_grad}\")\n",
        "    return result"
      ],
      "metadata": {
        "id": "RSgqEQNPZYWk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tensor = data_w_noise  # Исходный тензор\n",
        "# Ядро Таккера\n",
        "core_tensor = torch.tensor(np.random.randint(10, size=(r, r, r)), dtype=torch.double, requires_grad=True, device=device)\n",
        "\n",
        "# Факторы Таккера (те самые случайные матрицы требующие градиентной оптимизации)\n",
        "factors = [torch.tensor(np.random.randint(10, size=(size[i], r)),\n",
        "        dtype=torch.double, requires_grad=True, device=device) for i in range(len(size))]\n",
        "\n",
        "\n",
        "# Инициализация оптимизатора\n",
        "optimizer = TuckerOptimizer([core_tensor] + factors, lr=1e-3)\n",
        "\n",
        "\n",
        "for epoch in range(50):\n",
        "\n",
        "    print(f\"Core tensor requires_grad: {core_tensor.requires_grad}\")\n",
        "    for i, factor in enumerate(factors):\n",
        "        print(f\"Factor {i} requires_grad: {factor.requires_grad}\")\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # Перестроение тензора\n",
        "    approx_tensor = rebuild_tensor(core_tensor, factors)\n",
        "\n",
        "    # Вычисление квадратичного лосса\n",
        "    loss = F.mse_loss(approx_tensor, tensor)\n",
        "\n",
        "    # Вычисление градиентов\n",
        "    loss.backward()\n",
        "\n",
        "    print(loss)\n",
        "    # Шаг оптимизации\n",
        "    optimizer.step()\n",
        "    print(loss)\n",
        "\n",
        "\n",
        "    if epoch % 10 == 0:\n",
        "        print(f'Epoch {epoch + 1}, Loss: {loss.item()}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "AQSBVb7z1TxI",
        "outputId": "ea29d993-7edf-48e8-fab2-e5620c930b2e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Core tensor requires_grad: True\n",
            "Factor 0 requires_grad: True\n",
            "Factor 1 requires_grad: True\n",
            "Factor 2 requires_grad: True\n",
            "Core tensor requires_grad: True\n",
            "Factor 0 requires_grad: True\n",
            "Factor 1 requires_grad: True\n",
            "Factor 2 requires_grad: True\n",
            "result tensor requires_grad: True\n",
            "tensor(1.1986e+09, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "tensor([[[  -84291.0126,  -999485.8621,  -576736.4254, -1003162.8396,\n",
            "           -323033.3616],\n",
            "         [  670754.8501,  -241213.0115,   187587.1444,  -245517.7817,\n",
            "            476300.4326],\n",
            "         [  209319.6851,  -611716.7582,  -229383.7936,  -674428.1402,\n",
            "            -27256.3777],\n",
            "         [    2726.5110,  -724843.5425,  -438011.0033,  -690819.7143,\n",
            "           -223279.9614],\n",
            "         [ -132704.6594, -1389867.5332,  -852601.4254, -1367610.2119,\n",
            "           -459350.4063]],\n",
            "\n",
            "        [[ 1349603.9791,   938714.7154,  1238817.2858,   973544.1509,\n",
            "           1389741.0332],\n",
            "         [ 2113913.3086,  1737131.1509,  2050416.0155,  1765323.1649,\n",
            "           2211849.4448],\n",
            "         [ 1561900.6936,  1213624.0978,  1504516.0714,  1193929.1388,\n",
            "           1615526.6615],\n",
            "         [ 1176045.2592,   846585.7059,  1066527.4899,   902686.0624,\n",
            "           1179571.5027],\n",
            "         [ 1946935.3558,  1398072.9411,  1781874.6432,  1445445.7664,\n",
            "           2001113.7644]],\n",
            "\n",
            "        [[  912457.3266,   577714.5358,   809175.7798,   610318.3227,\n",
            "            908159.7047],\n",
            "         [ 1497330.5500,  1205258.1598,  1445290.1864,  1232863.4164,\n",
            "           1543140.2621],\n",
            "         [ 1069235.0475,   804579.6080,  1022154.9098,   789602.1052,\n",
            "           1083778.5598],\n",
            "         [  782085.7355,   512031.8330,   681338.7853,   566344.2629,\n",
            "            758388.8958],\n",
            "         [ 1310165.5233,   869678.9009,  1171113.1554,   915957.9239,\n",
            "           1312287.3387]],\n",
            "\n",
            "        [[ -241988.3543, -1229761.1009,  -777053.1827, -1158354.4375,\n",
            "           -472714.1539],\n",
            "         [  463592.4077,  -543728.3537,   -69758.7651,  -467009.6993,\n",
            "            272058.4626],\n",
            "         [  -11888.9473,  -934486.9986,  -496723.0919,  -925968.9782,\n",
            "           -244589.0886],\n",
            "         [ -153241.9997,  -948909.6073,  -626579.7815,  -857399.6393,\n",
            "           -376076.7498],\n",
            "         [ -338492.0958, -1697521.0945, -1114076.7876, -1578038.2374,\n",
            "           -657053.5073]],\n",
            "\n",
            "        [[  892843.0567,   112332.1134,   533673.3097,   118912.2018,\n",
            "            763115.6893],\n",
            "         [ 1859553.5809,  1126504.7523,  1553955.9685,  1129213.3926,\n",
            "           1805870.5579],\n",
            "         [ 1223603.2677,   565314.2516,   945335.3547,   503027.9642,\n",
            "           1115169.3464],\n",
            "         [  818265.8806,   203003.4661,   495140.1393,   255273.3573,\n",
            "            681084.4681],\n",
            "         [ 1252518.2917,   201075.2532,   742053.2550,   232146.1637,\n",
            "           1090768.7472]]], dtype=torch.float64)\n",
            "tensor([[  2099749.0342,   2361700.1505,   2876858.2395,   2307897.1454,\n",
            "           2528367.4128],\n",
            "        [ 12417365.1664,  13482548.6373,  16158898.6179,  13020104.3982,\n",
            "          13338414.4978],\n",
            "        [  1456463.4789,   1693534.7780,   1947510.3446,   1638176.4540,\n",
            "           1826530.3922],\n",
            "        [-21247022.7323, -22475270.9684, -27201669.2385, -21873925.9303,\n",
            "         -22027591.0726],\n",
            "        [ 10939452.6944,  12095015.6769,  14487724.2652,  11682326.4674,\n",
            "          11924563.9860],\n",
            "        [ -5581015.0610,  -5813973.7088,  -7041998.0973,  -5596019.3866,\n",
            "          -5565896.6049],\n",
            "        [  3277207.5885,   3722573.2390,   4380001.9258,   3515347.3105,\n",
            "           3649561.6893],\n",
            "        [  3500340.6682,   3885659.5472,   4647551.2173,   3743526.9493,\n",
            "           3933423.8553],\n",
            "        [ -6770159.3737,  -6977301.4171,  -8574869.1486,  -6834335.6663,\n",
            "          -6804856.4498],\n",
            "        [ -3959793.0222,  -3996328.6012,  -4919343.7484,  -3900695.5108,\n",
            "          -3745194.4054]], dtype=torch.float64)\n",
            "tensor([[ 3768988.1529,  3082080.2027,  3241277.9629,  3902410.3072,\n",
            "          3263667.8624],\n",
            "        [ 2192176.5712,  1778346.2174,  1807531.1916,  2205347.4548,\n",
            "          1964240.7653],\n",
            "        [-4058798.9052, -2962358.9590, -3801400.6796, -4114431.4257,\n",
            "         -2963860.5830],\n",
            "        [-3474178.3749, -2416257.2221, -3387695.7283, -3486446.1174,\n",
            "         -2299303.3593],\n",
            "        [-8069714.4509, -5971617.1741, -7474150.7003, -8157794.7657,\n",
            "         -5974313.5741],\n",
            "        [-8571322.3706, -6324244.8176, -7906734.3101, -8597802.9584,\n",
            "         -6376886.4710],\n",
            "        [-2183757.0968, -1475590.2396, -2217598.2024, -2220013.6102,\n",
            "         -1319071.6846],\n",
            "        [-1320891.0131,  -762679.7338, -1354210.3403, -1286933.2061,\n",
            "          -674770.1444],\n",
            "        [ -452236.3546,  -235929.7017,  -550860.7293,  -463425.3827,\n",
            "           -92258.7142],\n",
            "        [  765712.4665,   729857.2763,   554820.4049,   855220.0980,\n",
            "           876349.7775],\n",
            "        [ 4663807.0622,  3710320.0159,  3967897.8135,  4726218.9552,\n",
            "          3973747.4309],\n",
            "        [-2011758.7976, -1390860.8897, -1923870.6312, -2035622.6473,\n",
            "         -1315706.3737],\n",
            "        [ 5269707.3340,  4163787.0643,  4578282.2913,  5316342.7571,\n",
            "          4424435.0223],\n",
            "        [ 1509549.1452,  1315556.3847,  1144924.9505,  1518980.2447,\n",
            "          1523059.3634],\n",
            "        [ 5230451.3308,  4104594.0546,  4573855.1342,  5304536.1717,\n",
            "          4372417.6653],\n",
            "        [-1186056.2069,  -736597.1859, -1192972.6170, -1171147.5308,\n",
            "          -666053.3312],\n",
            "        [-2830419.8925, -2027204.4184, -2723532.8903, -2841008.8202,\n",
            "         -1957670.2518],\n",
            "        [ 2101341.2838,  1745645.1915,  1719027.2209,  2083963.0162,\n",
            "          1935333.3404],\n",
            "        [ 3845960.1457,  3086489.9163,  3340686.2520,  3928265.7677,\n",
            "          3273270.8414],\n",
            "        [-6718184.2013, -4974732.4257, -6166790.5646, -6764527.3508,\n",
            "         -5055133.9000]], dtype=torch.float64)\n",
            "tensor([[ 2098220.3411,  1716432.4003,  1691610.5809,  2174518.3188,\n",
            "          3054342.5455],\n",
            "        [ -487020.5734,  -543209.7162,  -476434.6451,  -698840.8078,\n",
            "          -888809.4912],\n",
            "        [-1102552.7147, -1043553.1953,  -998913.0257, -1406226.2905,\n",
            "         -1902287.7059],\n",
            "        [ 1890860.5042,  1557503.4079,  1511841.5679,  1951469.4672,\n",
            "          2705067.3290],\n",
            "        [ 1578380.8207,  1310381.0169,  1251008.4501,  1648372.2416,\n",
            "          2229996.2888],\n",
            "        [  912733.4183,   698472.8399,   711313.4120,   886078.1356,\n",
            "          1261241.3341],\n",
            "        [ 1084920.2530,   907826.0143,   855427.3086,  1105247.8997,\n",
            "          1509288.3567],\n",
            "        [ -186378.2395,  -175220.8112,  -185399.7103,  -293373.9915,\n",
            "          -439169.4076],\n",
            "        [-2925257.0569, -2599035.2671, -2475141.8782, -3392592.8012,\n",
            "         -4606588.0982],\n",
            "        [-2184836.4671, -1950593.9719, -1880062.8312, -2527327.0975,\n",
            "         -3483474.4816],\n",
            "        [-4499553.3412, -3960033.0746, -3791556.7940, -5152981.8884,\n",
            "         -7015865.8076],\n",
            "        [ 4190739.9740,  3554322.4090,  3422210.9418,  4560724.4736,\n",
            "          6230289.2981],\n",
            "        [  594956.6354,   402509.0734,   425467.3895,   510373.5455,\n",
            "           729819.2437],\n",
            "        [ -570526.8578,  -571579.8600,  -513999.7581,  -769020.3097,\n",
            "          -984709.6135],\n",
            "        [ 1710766.3855,  1400769.9131,  1357761.7005,  1762632.8726,\n",
            "          2425226.5512],\n",
            "        [ 1579281.4773,  1291762.1956,  1259575.0023,  1659389.1117,\n",
            "          2263530.9996],\n",
            "        [ 5316607.8341,  4521401.7472,  4360760.2783,  5838167.5415,\n",
            "          7971245.0899],\n",
            "        [-1008826.8310,  -932070.2184,  -918861.4774, -1251400.0935,\n",
            "         -1764330.3221],\n",
            "        [   71705.5629,   -43519.4876,    15257.1260,   -91494.5024,\n",
            "           -29476.5957],\n",
            "        [ -474697.7002,  -534867.1361,  -461393.9580,  -717249.6886,\n",
            "          -910918.5039],\n",
            "        [  788161.3362,   670260.6865,   612939.0488,   805220.9844,\n",
            "          1044902.0181],\n",
            "        [-1468684.7623, -1338663.4586, -1308362.7809, -1756652.8060,\n",
            "         -2441081.8134],\n",
            "        [-4064500.3645, -3561094.3235, -3405690.3218, -4651297.0155,\n",
            "         -6349084.9872],\n",
            "        [ 1109090.8716,   862122.2711,   858685.6025,  1099862.0356,\n",
            "          1527039.9109],\n",
            "        [-1449051.2124, -1348458.1829, -1283734.9218, -1756999.6903,\n",
            "         -2416931.0375],\n",
            "        [ 1277549.9043,  1064340.9805,  1021076.9541,  1311583.3820,\n",
            "          1795292.0038],\n",
            "        [ -952967.4324,  -864135.2363,  -802901.8102, -1151945.8605,\n",
            "         -1527055.4099],\n",
            "        [ 1747552.0083,  1426465.2278,  1404066.7490,  1825167.0805,\n",
            "          2541244.1514],\n",
            "        [ -843901.7374,  -804162.9505,  -737741.2678, -1058474.9678,\n",
            "         -1393656.7051],\n",
            "        [ -594552.8915,  -573174.7076,  -524279.9955,  -791866.3709,\n",
            "         -1042961.3802]], dtype=torch.float64)\n",
            "tensor(1.1986e+09, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
            "Epoch 1, Loss: 1198635888.4458444\n",
            "Core tensor requires_grad: True\n",
            "Factor 0 requires_grad: True\n",
            "Factor 1 requires_grad: True\n",
            "Factor 2 requires_grad: True\n",
            "Core tensor requires_grad: True\n",
            "Factor 0 requires_grad: True\n",
            "Factor 1 requires_grad: True\n",
            "Factor 2 requires_grad: True\n",
            "result tensor requires_grad: True\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "Trying to backward through the graph a second time (or directly access saved tensors after they have already been freed). Saved intermediate values of the graph are freed when you call .backward() or autograd.grad(). Specify retain_graph=True if you need to backward through the graph a second time or if you need to access saved tensors after calling backward.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-428-ed30b9c78e04>\u001b[0m in \u001b[0;36m<cell line: 14>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0;31m# Вычисление градиентов\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    579\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    580\u001b[0m             )\n\u001b[0;32m--> 581\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    582\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    583\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    345\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    346\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 347\u001b[0;31m     _engine_run_backward(\n\u001b[0m\u001b[1;32m    348\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    349\u001b[0m         \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py\u001b[0m in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    823\u001b[0m         \u001b[0munregister_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_register_logging_hooks_on_whole_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    824\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 825\u001b[0;31m         return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    826\u001b[0m             \u001b[0mt_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m         )  # Calls into the C++ engine to run the backward pass\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Trying to backward through the graph a second time (or directly access saved tensors after they have already been freed). Saved intermediate values of the graph are freed when you call .backward() or autograd.grad(). Specify retain_graph=True if you need to backward through the graph a second time or if you need to access saved tensors after calling backward."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Оптимизация\n",
        "# for epoch in range(50):\n",
        "#     def closure():\n",
        "#         optimizer.zero_grad()\n",
        "#         # Перестроение тензора на основе текущего ядра и факторов\n",
        "#         approx_tensor = rebuild_tensor(core_tensor, factors)\n",
        "#         # Вычисление квадратичного лосса\n",
        "#         loss = F.mse_loss(approx_tensor, tensor)\n",
        "#         loss.backward()\n",
        "#         return loss\n",
        "\n",
        "#     loss = optimizer.step(closure)\n",
        "#     if epoch%10 == 0:\n",
        "#         print(f'Epoch {epoch + 1}, Loss: {loss.item()}')"
      ],
      "metadata": {
        "id": "5GJcJAncF9lz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Za8JKgR-Falk"
      },
      "source": [
        "## 5 Приведите сравнение скорости работы и ошибки восстановления методом из пакета и реализованного градиентного\n",
        "Сравнение может считаться ± объективным с размером выборки от 10."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mOGKW9RHFa5D"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}