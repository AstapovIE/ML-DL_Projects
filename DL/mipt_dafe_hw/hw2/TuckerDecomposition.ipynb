{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qjl6x6og3uXH"
      },
      "source": [
        "# HW 2 - Разложение матриц градиентным методом"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sv79QFb_-oNZ"
      },
      "source": [
        "Цель задания: В ходе реализации [разложения Таккера](https://proceedings.neurips.cc/paper/2018/file/45a766fa266ea2ebeb6680fa139d2a3d-Paper.pdf) градиентным методом освоить pyTorch и реализовать подходы оптимизации параметров модели (в отсутствии готовых решений)."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install tensorly"
      ],
      "metadata": {
        "id": "7cETheA1BbT0"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1HUSrylpBwYn"
      },
      "source": [
        "[Более-менее внятное описание алгоритма канонического разложения](https://www.alexejgossmann.com/tensor_decomposition_tucker/) - само аналитическое разложение вам реализовывать НЕ НУЖНО"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "P1PuoBtG7iw7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e882f33a-3386-41f7-8c21-e42cf1a26a43"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7dcb80f9d0d0>"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "import random\n",
        "import time\n",
        "import torch\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import tensorly as tl\n",
        "from tensorly.decomposition import tucker\n",
        "from tensorly.metrics.regression import RMSE\n",
        "\n",
        "import scipy.sparse as sparse\n",
        "from scipy.sparse.linalg import spsolve\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from matplotlib import pyplot as plt\n",
        "from numpy.linalg import svd, matrix_rank, pinv, inv\n",
        "from scipy.linalg import eigh, eig\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from tqdm.notebook import tqdm\n",
        "from torch import nn\n",
        "\n",
        "import math\n",
        "from torch.optim.optimizer import Optimizer\n",
        "import torch.nn.functional as F\n",
        "\n",
        "torch.manual_seed(0)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OdgOrKhyCS6r",
        "outputId": "572bdd35-25f5-445d-f117-e77185cbccb8"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6LfhKpuX7htE"
      },
      "source": [
        "## 1 Создайте 3х мерный тензор\n",
        "Размер тензора не меньше 100 по каждой из размерностей.\n",
        "\n",
        "Заполните случайными целыми числами в диапазоне от 0 до 9."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ap1Ozn7P8-Yj"
      },
      "source": [
        "Примечание: разложение будет корректно работать со случайным тензором, только если изначально создавать случайные ядро и матрицы, а потом по ним формировать тензор. Работайте с типом *torch.Tensor.double*."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # Функция, восстанавливающая тензор по ядру и матрицам\n",
        "# def repair_tensor(G_, U):\n",
        "#     # data - восстановленный тензор из матриц и ядра\n",
        "#     # U - список матриц\n",
        "#     # G_ - ядро разложения\n",
        "#     a1 = tl.tenalg.mode_dot(tensor=tl.tensor(G_.detach().numpy()), matrix_or_vector=tl.tensor(U[0].detach().numpy()), mode=0, transpose=False)\n",
        "#     a2 = tl.tenalg.mode_dot(tensor=a1, matrix_or_vector=tl.tensor(U[1].detach().numpy()), mode=1, transpose=False)\n",
        "#     a3 = tl.tenalg.mode_dot(tensor=a2, matrix_or_vector=tl.tensor(U[2].detach().numpy()), mode=2, transpose=False)\n",
        "#     return torch.tensor(a3, dtype=torch.double, requires_grad=True, device=device)"
      ],
      "metadata": {
        "id": "IXgWKromr6Vi"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "id": "5SzHzteOROQQ"
      },
      "outputs": [],
      "source": [
        "# Создадим тензор: размер тензора и r задаётся\n",
        "def get_tensor(size=(100,200,150), r=10):\n",
        "    # data - тензор с заданной размерностью\n",
        "    # U - список матриц\n",
        "    U = [torch.randn(size[i], r, dtype=torch.double) for i in range(len(size))]\n",
        "    # G - ядро разложения\n",
        "    G = torch.randint(0, 10, (r, r, r), dtype=torch.double)\n",
        "    # data = rebuild_tensor(G, U)\n",
        "    ata = torch.einsum('ia,jb,kc,abc->ijk', U[0], U[1], U[2], G)\n",
        "\n",
        "    return data, U, G"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def rebuild_tensor(G_, U):\n",
        "    result = G_\n",
        "    for i, u in enumerate(U):\n",
        "        result = torch.tensordot(result, u, dims=([0], [1]))\n",
        "    # print(f\"result tensor requires_grad: {result.requires_grad}\")\n",
        "    return result"
      ],
      "metadata": {
        "id": "Q4Vqcg71SaaE"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EFuFlp2n78Tz"
      },
      "source": [
        "Сгенерируйте тензор и добавьте к нему случайный шум с размерностью *1e-2*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "FnUbbsYSdrsw",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 315
        },
        "outputId": "ac8fde37-2cc3-4424-d38b-7d37f21ccdf9"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'U1' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-57-ea080ecd1d69>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mU\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mG\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mu\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mU\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mG\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-55-2de3bbea8781>\u001b[0m in \u001b[0;36mget_tensor\u001b[0;34m(size, r)\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mG\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdouble\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;31m# data = rebuild_tensor(G, U)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meinsum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'ia,jb,kc,abc->ijk'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mU1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mU2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mU3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mG\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mU\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mG\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'U1' is not defined"
          ]
        }
      ],
      "source": [
        "size = (100, 200, 300)\n",
        "r = 10\n",
        "\n",
        "data, U, G = get_tensor(size, r)\n",
        "data.shape, [u.shape for u in U], G.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N70Xy_6u9RFa"
      },
      "outputs": [],
      "source": [
        "# noise = torch.tensor(np.random.normal(0, 1e-2, size=size), dtype=torch.double, device=device)\n",
        "# data_w_noise = data + noise\n",
        "# print(f\"data_w_noise requires_grad: {data_w_noise.requires_grad}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_w_noise = data + torch.randn_like(data) * 1e-2\n",
        "\n",
        "print(f\"data_w_noise requires_grad: {data_w_noise.requires_grad}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DZz0iCIYH5oJ",
        "outputId": "4d25be94-3b17-44b8-e30a-c908f4274063"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "data_w_noise requires_grad: False\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kp75_Ad29RL5"
      },
      "source": [
        "Вопрос:\n",
        "Почему задание не имеет смысла для полностью случайного тензора и зачем добавлять шум? *не отвечать нельзя*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5VLMaT5wyE11"
      },
      "source": [
        "Ответ:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TzninpMYD_hd"
      },
      "source": [
        "## 2 Реализуйте метод для восстановления тензора по разложению"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "id": "YDTx9ZbYD-_S"
      },
      "outputs": [],
      "source": [
        "# Функция, восстанавливающая тензор по ядру и матрицам (для результата из библы tensorly)\n",
        "def repair_tensor_for_ndarray(G_, U):\n",
        "    # data - восстановленный тензор из матриц и ядра\n",
        "    # U - список матриц\n",
        "    # G_ - ядро разложения\n",
        "    a1 = tl.tenalg.mode_dot(tensor=tl.tensor(G_), matrix_or_vector=tl.tensor(U[0]), mode=0, transpose=False)\n",
        "    a2 = tl.tenalg.mode_dot(tensor=a1, matrix_or_vector=tl.tensor(U[1]), mode=1, transpose=False)\n",
        "    a3 = tl.tenalg.mode_dot(tensor=a2, matrix_or_vector=tl.tensor(U[2]), mode=2, transpose=False)\n",
        "    return torch.tensor(a3, dtype=torch.double)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MKqzxtaE-F16"
      },
      "source": [
        "## 3 Сделайте разложение библиотечным методом\n",
        "Пакет можете брать любой"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "id": "Hlp4Jh3--fKh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "49cce1b8-76ff-4c8f-84db-38ca5479e21d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10, 10, 10) [(100, 10), (200, 10), (150, 10)]\n"
          ]
        }
      ],
      "source": [
        "from tensorly.decomposition import tucker\n",
        "from tensorly import tucker_to_tensor\n",
        "\n",
        "# использую tucker from tensorly\n",
        "# data_ndarray = data_w_noise.detach().cpu().numpy()\n",
        "data_ndarray = data_w_noise.detach().numpy()\n",
        "core, factors = tucker(tl.tensor(data_ndarray), [r, r, r])\n",
        "print(core.shape, [u.shape for u in factors])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wMw1x8w8-lsh"
      },
      "source": [
        "Не забудьте померить ошибку разложения по метрике MSE"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def MSE(tensor1, tensor2):\n",
        "    delta = tensor1-tensor2\n",
        "    delta *= delta\n",
        "    mse = delta.sum() / delta.numel()\n",
        "    return mse.item()"
      ],
      "metadata": {
        "id": "QaBCzVUcY5BH"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "id": "HWkdb7Ip-mL3"
      },
      "outputs": [],
      "source": [
        "repaired_data = repair_tensor_for_ndarray(core, factors)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "MSE(repaired_data, data_w_noise)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xXz8pgtLXo09",
        "outputId": "2818264f-bd53-48d0-cef3-80074fef2f64"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "9.993324875311374e-05"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ibOgeEgfD1wm"
      },
      "source": [
        "## 4 Реализуйте разложение градиентным методом"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GstBYmiBF7A6"
      },
      "source": [
        "### 4.1 Реализуйте *optimizer*\n",
        "Можно взять из исходников *PyTorch* и отнаследоваться от *torch.optim.optimizer*.\n",
        "Используйте квадратичный *Loss*."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "id": "Mxrtt60hF6xb"
      },
      "outputs": [],
      "source": [
        "# class Opt(Optimizer):\n",
        "\n",
        "#     def __init__(self, params, lr=1e-3, ...):\n",
        "#         super().__init__(params, defaults)\n",
        "\n",
        "#     def step(self):\n",
        "#         return loss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8GSolH5dEJba"
      },
      "source": [
        "### 4.2 Реализуйте цикл оптимизации параметров"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P6UWpuERFTn8"
      },
      "source": [
        "Стоит параметры оптимизировать сразу на GPU"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class TuckerOptimizer(Optimizer):\n",
        "    def __init__(self, params, lr=1e-3):\n",
        "        defaults = {'lr': lr}\n",
        "        super().__init__(params, defaults)\n",
        "\n",
        "    # по мотивам доков sgd optimizer\n",
        "    def step(self):\n",
        "        for group in self.param_groups:\n",
        "            for param in group['params']:\n",
        "                if param.grad is not None:\n",
        "                    param.data -= group['lr'] * param.grad.data"
      ],
      "metadata": {
        "id": "pz_Gt7mN1Tu8"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(data, rank, lr=1e-3, epochs=1000):\n",
        "    history = []\n",
        "\n",
        "    factors = [torch.randn(data.size(i), rank[i], requires_grad=True, dtype=torch.double) for i in range(3)]\n",
        "    core = torch.randn(rank, requires_grad=True, dtype=torch.double)\n",
        "\n",
        "    # optimizer = TuckerOptimizer([{'params': factors + [core]}], lr=lr)\n",
        "    optimizer = TuckerOptimizer([core] + factors, lr=1e-3)\n",
        "    loss_fn = torch.nn.MSELoss()\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        approx_tensor = rebuild_tensor(core_tensor, factors)\n",
        "        loss = loss_fn(approx_tensor, data)\n",
        "        loss.backward()\n",
        "\n",
        "        optimizer.step()\n",
        "\n",
        "        if epoch % 100 == 0:\n",
        "            history.append(loss.item())\n",
        "            print(f'Epoch {epoch + 1}, Loss: {loss.item()}')\n",
        "\n",
        "    return core, factors, history\n"
      ],
      "metadata": {
        "id": "7VNTESw-M7Rd"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tensor0 = data_w_noise  # Исходный тензор\n",
        "\n",
        "core, fac, history = train(tensor0, [10,10,10], lr=1e-9, epochs=2000)\n",
        "\n",
        "result = rebuild_tensor(core, fac)\n",
        "\n",
        "mse = torch.nn.functional.mse_loss(result, tensor0)\n",
        "print(f\"MSE после градиентного разложения: {mse.item():.6e}\")\n",
        "plt.plot(np.arange(20), history)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "id": "BGahONXxNrTH",
        "outputId": "056acf09-c7ea-49fc-adfb-f9b15668f014"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss: 165878917.5611736\n",
            "Epoch 101, Loss: nan\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-67-2657f9d967ed>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtensor0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_w_noise\u001b[0m  \u001b[0;31m# Исходный тензор\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mcore\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfac\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-9\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrebuild_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfac\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-66-a5c40edce794>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(data, rank, lr, epochs)\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mapprox_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrebuild_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfactors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mapprox_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    579\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    580\u001b[0m             )\n\u001b[0;32m--> 581\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    582\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    583\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    345\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    346\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 347\u001b[0;31m     _engine_run_backward(\n\u001b[0m\u001b[1;32m    348\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    349\u001b[0m         \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py\u001b[0m in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    823\u001b[0m         \u001b[0munregister_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_register_logging_hooks_on_whole_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    824\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 825\u001b[0;31m         return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    826\u001b[0m             \u001b[0mt_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m         )  # Calls into the C++ engine to run the backward pass\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "b-w68bcZN8Cf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "O0XD7bx9N8ES"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tensor0 = data_w_noise  # Исходный тензор\n",
        "\n",
        "rank = [10,10,10]\n",
        "factors = [torch.randn(data.size(i), rank[i], requires_grad=True, dtype=torch.double) for i in range(3)]\n",
        "core_tensor = torch.randn(rank, requires_grad=True, dtype=torch.double)\n",
        "\n",
        "\n",
        "# optimizer = TuckerOptimizer([core_tensor] + factors, lr=1e-3)\n",
        "# optimizer = torch.optim.Adam([core_tensor] + factors, lr=1e-3)\n",
        "optimizer = TuckerOptimizer([{'params': factors + [core_tensor]}], lr=1e-3)\n",
        "# loss_fn = torch.nn.MSELoss()\n",
        "loss_fn = torch.nn.functional.mse_loss\n",
        "\n",
        "history = []\n",
        "for epoch in range(10000):\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    approx_tensor = rebuild_tensor(core_tensor, factors)\n",
        "    # approx_tensor = torch.einsum('ia,jb,kc,abc->ijk', factors[0], factors[1], factors[2], core_tensor)\n",
        "\n",
        "    loss = loss_fn(approx_tensor, tensor0)\n",
        "    loss.backward()\n",
        "\n",
        "    optimizer.step()\n",
        "\n",
        "    if epoch % 100 == 0:\n",
        "        history.append(loss.item())\n",
        "        print(f'Epoch {epoch + 1}, Loss: {loss.item()}')\n",
        "\n",
        "plt.plot(np.arange(100), history)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "AQSBVb7z1TxI",
        "outputId": "de20d3c6-a5e7-4878-f951-f556ef043a89"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'torch.Tensor'>\n",
            "tensor0 requires_grad: False\n",
            "Epoch 1, Loss: 32739.172087994415\n",
            "Epoch 101, Loss: 32209.82872123223\n",
            "Epoch 201, Loss: 32050.68718579427\n",
            "Epoch 301, Loss: 31975.143360694095\n",
            "Epoch 401, Loss: 31928.380850725087\n",
            "Epoch 501, Loss: 31887.9435883454\n",
            "Epoch 601, Loss: 31818.782886890443\n",
            "Epoch 701, Loss: 31331.693547811832\n",
            "Epoch 801, Loss: 8113.2035991015155\n",
            "Epoch 901, Loss: 7977.613937121839\n",
            "Epoch 1001, Loss: 7958.483963265756\n",
            "Epoch 1101, Loss: 7946.863332330446\n",
            "Epoch 1201, Loss: 7938.284538723272\n",
            "Epoch 1301, Loss: 7930.922286865917\n",
            "Epoch 1401, Loss: 7923.760913683998\n",
            "Epoch 1501, Loss: 7916.024064234158\n",
            "Epoch 1601, Loss: 7906.922288113009\n",
            "Epoch 1701, Loss: 7895.484912380404\n",
            "Epoch 1801, Loss: 7880.406692716654\n",
            "Epoch 1901, Loss: 7859.905093222146\n",
            "Epoch 2001, Loss: 7831.648513946093\n",
            "Epoch 2101, Loss: 7792.885952067904\n",
            "Epoch 2201, Loss: 7740.874834124008\n",
            "Epoch 2301, Loss: 7673.418267296528\n",
            "Epoch 2401, Loss: 7589.215995967727\n",
            "Epoch 2501, Loss: 7488.684859363673\n",
            "Epoch 2601, Loss: 7375.798719891631\n",
            "Epoch 2701, Loss: 7256.879773932818\n",
            "Epoch 2801, Loss: 7133.643664859945\n",
            "Epoch 2901, Loss: 7000.819383711675\n",
            "Epoch 3001, Loss: 6852.2360270339495\n",
            "Epoch 3101, Loss: 6684.71324758832\n",
            "Epoch 3201, Loss: 6496.160137754786\n",
            "Epoch 3301, Loss: 6283.261817409713\n",
            "Epoch 3401, Loss: 6041.539961794767\n",
            "Epoch 3501, Loss: 5769.535771544116\n",
            "Epoch 3601, Loss: 5477.904907138406\n",
            "Epoch 3701, Loss: 5188.1534794652725\n",
            "Epoch 3801, Loss: 4913.202000368446\n",
            "Epoch 3901, Loss: 4652.95096162572\n",
            "Epoch 4001, Loss: 4405.790940462944\n",
            "Epoch 4101, Loss: 4169.0772783416205\n",
            "Epoch 4201, Loss: 3936.548149331787\n",
            "Epoch 4301, Loss: 3702.285664563253\n",
            "Epoch 4401, Loss: 3464.3870009835205\n",
            "Epoch 4501, Loss: 3224.9348472917786\n",
            "Epoch 4601, Loss: 2986.54515424602\n",
            "Epoch 4701, Loss: 2746.6565543211923\n",
            "Epoch 4801, Loss: 2495.376220381807\n",
            "Epoch 4901, Loss: 2220.8717966049003\n",
            "Epoch 5001, Loss: 1922.7288769058564\n",
            "Epoch 5101, Loss: 1627.830928202009\n",
            "Epoch 5201, Loss: 1366.9922587642016\n",
            "Epoch 5301, Loss: 1140.283747774963\n",
            "Epoch 5401, Loss: 938.1300196902272\n",
            "Epoch 5501, Loss: 756.1884373134759\n",
            "Epoch 5601, Loss: 587.8584911977417\n",
            "Epoch 5701, Loss: 425.49384394587963\n",
            "Epoch 5801, Loss: 275.30840228827225\n",
            "Epoch 5901, Loss: 158.2068010505582\n",
            "Epoch 6001, Loss: 84.39818233341663\n",
            "Epoch 6101, Loss: 44.25497234097776\n",
            "Epoch 6201, Loss: 23.588577129804452\n",
            "Epoch 6301, Loss: 12.91904844590374\n",
            "Epoch 6401, Loss: 7.274066341744412\n",
            "Epoch 6501, Loss: 4.199626151061616\n",
            "Epoch 6601, Loss: 2.4779363301569655\n",
            "Epoch 6701, Loss: 1.4892641398082083\n",
            "Epoch 6801, Loss: 0.9088920342712874\n",
            "Epoch 6901, Loss: 0.5617175836425292\n",
            "Epoch 7001, Loss: 0.35072454825523985\n",
            "Epoch 7101, Loss: 0.22080455428079565\n",
            "Epoch 7201, Loss: 0.13994554025063652\n",
            "Epoch 7301, Loss: 0.08918307128254233\n",
            "Epoch 7401, Loss: 0.0570914625363403\n",
            "Epoch 7501, Loss: 0.03668876483127814\n",
            "Epoch 7601, Loss: 0.023658162847758048\n",
            "Epoch 7701, Loss: 0.015304912484461102\n",
            "Epoch 7801, Loss: 0.00993366968611619\n",
            "Epoch 7901, Loss: 0.00647108347175913\n",
            "Epoch 8001, Loss: 0.004234106838910327\n",
            "Epoch 8101, Loss: 0.002786252415775164\n",
            "Epoch 8201, Loss: 0.0018476349175981348\n",
            "Epoch 8301, Loss: 0.0012382754313972543\n",
            "Epoch 8401, Loss: 0.0008421631162835937\n",
            "Epoch 8501, Loss: 0.0005843676866113393\n",
            "Epoch 8601, Loss: 0.00041640730925617653\n",
            "Epoch 8701, Loss: 0.000306864513842755\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-ac5faf961c12>\u001b[0m in \u001b[0;36m<cell line: 24>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m     \u001b[0mapprox_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrebuild_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfactors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m     \u001b[0;31m# approx_tensor = torch.einsum('ia,jb,kc,abc->ijk', factors[0], factors[1], factors[2], core_tensor)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-6-b0f5939b2849>\u001b[0m in \u001b[0;36mrebuild_tensor\u001b[0;34m(G_, U)\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mG_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mu\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mU\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensordot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdims\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0;31m# print(f\"result tensor requires_grad: {result.requires_grad}\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/functional.py\u001b[0m in \u001b[0;36mtensordot\u001b[0;34m(a, b, dims, out)\u001b[0m\n\u001b[1;32m   1353\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1354\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1355\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_VF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensordot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdims_a\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdims_b\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[attr-defined]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1356\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1357\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_VF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensordot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdims_a\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdims_b\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[attr-defined]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Za8JKgR-Falk"
      },
      "source": [
        "## 5 Приведите сравнение скорости работы и ошибки восстановления методом из пакета и реализованного градиентного\n",
        "Сравнение может считаться ± объективным с размером выборки от 10."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "results = {'pocket': {'execution_time': [],\n",
        "                      'mse_values': []},\n",
        "           'gradient': {'execution_time': [],\n",
        "                        'mse_values': []}}\n",
        "\n",
        "sample_count = 10\n",
        "tensor_shape = (50, 100, 150)\n",
        "tensor_rank = 10\n",
        "\n",
        "noisy_tensors = []\n",
        "for _ in range(sample_count):\n",
        "    tensor_data, _, _ = get_tensor(size=tensor_shape, r=tensor_rank)\n",
        "    # шумим\n",
        "    noisy_tensors.append(tensor_data + torch.randn_like(tensor_data) * 1e-2)\n",
        "\n",
        "# градиент\n",
        "for tensor in noisy_tensors:\n",
        "    start_time = time.time()\n",
        "    core_tensor, factors, _ = train(tensor, rank=[tensor_rank]*3, lr=1e-3, epochs=2000)\n",
        "    approx_tensor = rebuild_tensor(core_tensor, factors)\n",
        "\n",
        "    mse_value = torch.nn.functional.mse_loss(approx_tensor, tensor).item()\n",
        "    duration = time.time() - start_time\n",
        "\n",
        "    results['gradient']['execution_time'].append(duration)\n",
        "    results['gradient']['mse_values'].append(mse_value)\n",
        "\n",
        "# пакет\n",
        "for tensor in noisy_tensors:\n",
        "    start_time = time.time()\n",
        "    core_tensor, factors = tucker(tl.tensor(tensor), rank=[tensor_rank]*3)\n",
        "    core_tensor = torch.tensor(core_tensor, dtype=torch.double)\n",
        "    factors = [torch.tensor(factor, dtype=torch.double) for factor in factors]\n",
        "\n",
        "    reconstructed_tensor = rebuild_tensor(core_tensor, factors)\n",
        "\n",
        "    # MSE\n",
        "    mse_value = torch.nn.functional.mse_loss(reconstructed_tensor, tensor).item()\n",
        "    duration = time.time() - start_time\n",
        "\n",
        "    results['pocket']['execution_time'].append(duration)\n",
        "    results['pocket']['mse_values'].append(mse_value)\n",
        "\n",
        "\n",
        "for method in results:\n",
        "    average_time = sum(results[method]['execution_time']) / sample_count\n",
        "    print(f\" Метод: {method}\")\n",
        "    print(f\" Среднее время выполнения: {average_time:.6f} сек\")\n",
        "    average_mse = sum(results[method]['mse_values']) / sample_count\n",
        "    print(f\" Средняя ошибка восстановления (MSE): {average_mse:.6f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "id": "I0zL8xRQQc4e",
        "outputId": "09437b1b-1d77-4b6c-f96c-8e1347760b24"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss: 178215676.31965435\n",
            "Epoch 101, Loss: nan\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-71-cb1bb6f8137f>\u001b[0m in \u001b[0;36m<cell line: 19>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtensor\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnoisy_tensors\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0mstart_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m     \u001b[0mcore_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfactors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrank\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtensor_rank\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3e-3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m     \u001b[0mapprox_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrebuild_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfactors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-66-a5c40edce794>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(data, rank, lr, epochs)\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mapprox_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrebuild_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfactors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mapprox_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    579\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    580\u001b[0m             )\n\u001b[0;32m--> 581\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    582\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    583\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    345\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    346\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 347\u001b[0;31m     _engine_run_backward(\n\u001b[0m\u001b[1;32m    348\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    349\u001b[0m         \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py\u001b[0m in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    823\u001b[0m         \u001b[0munregister_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_register_logging_hooks_on_whole_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    824\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 825\u001b[0;31m         return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    826\u001b[0m             \u001b[0mt_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m         )  # Calls into the C++ engine to run the backward pass\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "j3w2GLoOR-Ja"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pYp3Lq4XR-LX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "oWAQuBSzUPpd"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}